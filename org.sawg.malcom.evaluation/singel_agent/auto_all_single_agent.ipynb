{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T14:36:31.040018Z",
     "start_time": "2024-11-07T14:36:29.894219Z"
    }
   },
   "source": [
    "import os\n",
    "import logging\n",
    "import openai\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://a.fe8.cn/v1\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-jxGxEstKGNXlwD4gaFIIveFQOAWm7hRxUZth8k191o5m8DE4\"\n",
    "\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "                base_url=os.environ.get(\"OPENAI_API_BASE\"),\n",
    "                timeout=openai.Timeout(600, connect=600))\n",
    "\n",
    "def get_completion(prompt, model, temperature, message):\n",
    "    res = ''\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            # TODO 这里修改system设定\n",
    "            messages=[\n",
    "                {\"role\": \"system\",\n",
    "                 \"content\": message[0]},\n",
    "                {\"role\": \"user\", \"content\": prompt},\n",
    "            ],\n",
    "            temperature=temperature,\n",
    "            # max_tokens=4096,\n",
    "        )\n",
    "        res = response.choices[0].message.content\n",
    "        # 响应tokens数量\n",
    "        prompt_tokens_num = response.usage.prompt_tokens\n",
    "        output_tokens_num = response.usage.completion_tokens\n",
    "        return res, prompt_tokens_num, output_tokens_num\n",
    "    except openai.APIConnectionError as e:\n",
    "        logging.error(f'The server could not be reached, cause:{e.__cause__}')\n",
    "    except openai.RateLimitError as e:\n",
    "        logging.error('A 429 status code was received; we should back off a bit.')\n",
    "    except openai.APIStatusError as e:\n",
    "        logging.error(\n",
    "            f'Another non-200-range status code was received, status_code: {e.status_code}, error response: {e.response}')\n",
    "    except Exception as e:\n",
    "        logging.error(\n",
    "            f'Another error response: {e}')\n",
    "    return res, 0, 0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:36:31.046421Z",
     "start_time": "2024-11-07T14:36:31.041021Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def run_term_extraction(times):\n",
    "    \n",
    "    with open('assets/system_description.txt', 'r', encoding='utf-8') as f:\n",
    "        system_description = f.read()\n",
    "    \n",
    "        # chain of thought example\n",
    "    with open('assets/chain_of_thought_term_extraction.txt', 'r') as f:\n",
    "        chain_of_thought_term_extraction = f.read()\n",
    "\n",
    "    \n",
    "    with open('assets/requirement_architecture.json', 'r') as f:\n",
    "        requirement_file = f.read()\n",
    "    \n",
    "    message = [ 'You are an expert in requirement engineering.' +\n",
    "            'Requirement statements can be categorised into Functional Requirements and Non-Functional Requirements. ' +\n",
    "            'You will be provided with some requirement statements from User, which are for a system to be developed.' +\n",
    "            'The description of the system is here: ' + system_description +\n",
    "            'Your task is to extract Concepts and their Instances from the requirement statements.' +\n",
    "            'The requirements will be provided by User, please note that the requirements are not ordered, and one requirement may implicitly depend on other requirements. ' +\n",
    "            'Each requirement statement is identified by a unique GID (short for Global ID). ' +\n",
    "            'Please extract occurrences of the following from the requirement statements: \"GID\", \"Concepts\" and \"Instances\". ' +\n",
    "            'The rationale for your task is here: ' + chain_of_thought_term_extraction +\n",
    "            'The Output format should be in JSON only, no markdown permitted (no ```), no explain.' +\n",
    "            'Include only contents provided to you.']\n",
    "    \n",
    "    for i in range(times):\n",
    "        start = time.time()\n",
    "        model = \"gpt-4o\"\n",
    "        temperature = 0.2\n",
    "        prompt = requirement_file\n",
    "        res = get_completion(prompt, model=model, temperature=temperature, message=message)\n",
    "\n",
    "        print(f\"Iteration {i+1}:\")\n",
    "        print(f\"Time taken: {time.time() - start} seconds\")\n",
    "        print(res[0])  # gpt4的结果，看这里\n",
    "\n",
    "        with open(f'result/Term_extraction_result/single_term_extraction_result_{i+1}.json', 'w', encoding='utf-8') as f:\n",
    "            f.write(res[0])"
   ],
   "id": "a928453607cdf9e9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:38:05.405963Z",
     "start_time": "2024-11-07T14:36:31.048432Z"
    }
   },
   "cell_type": "code",
   "source": [
    "times = 100\n",
    "run_term_extraction(times)"
   ],
   "id": "42aab69611d87e52",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:38:05.412201Z",
     "start_time": "2024-11-07T14:38:05.405963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_dsl_extraction(times):\n",
    "    \n",
    "    with open('assets/system_description.txt', 'r', encoding='utf-8') as system_file:\n",
    "        system_description = system_file.read()\n",
    "    \n",
    "    # Few-shot example for dsl extraction\n",
    "    with open('assets/few_shot_example_dsl_extraction.txt', 'r', encoding='utf-8') as few_shot_dsl_file:\n",
    "        few_shot_example_dsl_extraction = few_shot_dsl_file.read()\n",
    "    \n",
    "    # chain of thought prompt for dsl extraction\n",
    "    with open('assets/chain_of_thought_dsl_extraction.txt', 'r') as cot_dsl_extraction:\n",
    "        chain_of_thought_dsl_extraction = cot_dsl_extraction.read()\n",
    "    with open(\"assets/requirement_architecture.json\", 'r', encoding='utf-8') as rq:\n",
    "        requirement_file = rq.read()\n",
    "  \n",
    "    for i in range(times):\n",
    "        \n",
    "        with open(f'result/Term_extraction_result/single_term_extraction_result_{i+1}.json', 'r', encoding='utf-8') as term_file:\n",
    "            extracted_terms = term_file.read()\n",
    "        message = [\n",
    "            'You are an expert in Model Driven Engineering (MDE). ' +\n",
    "            'You are experienced in creating \"Domain Specific Languages (DSLs)\" or \"metamodels\". ' +\n",
    "            'A metamodel contains the abstract syntax to capture the concepts for the system to be developed. ' +\n",
    "            'You have extensive experience in creating metamodels using the Ecore modeling language provided by the Eclipse Modeling Framework (EMF). ' +\n",
    "            'You are also an expert in creating metamodels using the Emfatic language (a textual syntax for Ecore) to create metamodels.' +\n",
    "            'Your job is to create a metamodel written in Emfatic based on the requirements provided to you in JSON every round. ' +\n",
    "            'The description of the system to be developed is here: ' + system_description +\n",
    "            'Previously, a Term model is extracted, in here: ' + extracted_terms +\n",
    "            'Here are some thinking processes to guide you: ' + chain_of_thought_dsl_extraction +\n",
    "            'Here are some examples of the extracted metamodels based on inputs:' + few_shot_example_dsl_extraction +\n",
    "            'Consider also the previous inputs from the User. ' +\n",
    "            'You must only include Emfatic code in your responses.' +\n",
    "            'Do not include any other contents that are not provided to you. ' +\n",
    "            'Please do not include explanations in your answers. In addition, no markdown is permitted (no ```). ',\n",
    "            ]   \n",
    "        start = time.time()\n",
    "        model = \"gpt-4o\"\n",
    "        temperature = 0.2\n",
    "        prompt = requirement_file\n",
    "        res = get_completion(prompt, model=model, temperature=temperature, message=message)\n",
    "\n",
    "        print(f\"Iteration {i+1}:\")\n",
    "        print(f\"Time taken: {time.time() - start} seconds\")\n",
    "        print(res[0])  # gpt4的结果，看这里\n",
    "\n",
    "        with open(f'result/DSL_extraction_result/single_DSL_extraction_result_{i+1}.emf', 'w', encoding='utf-8') as f:\n",
    "            f.write(res[0])\n"
   ],
   "id": "72cea2c694d6a867",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:38:17.315171Z",
     "start_time": "2024-11-07T14:38:05.414210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_dsl_extraction(times)"
   ],
   "id": "f515fc94653dc82",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:38:17.323583Z",
     "start_time": "2024-11-07T14:38:17.317197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_dsl_trace_extraction(times):   \n",
    "    message = [\n",
    "    'You are an expert in Model Driven Engineering (MDE). ' +\n",
    "    'Your job is to generate a traceability JSON element based on the Emfatic code and the requirement in JSON provided by User  ' +\n",
    "    'In the Emfatic code provided to you by DSL_Summariser, you shall identify which class, attributes, references and operations are created, based on the requirement JSON provided by User' +\n",
    "    'Your answer should be in the following JSON format : ' +\n",
    "    '{\"requirement_gid\" : ${the gid of the requirement provided by User}, ' +\n",
    "    '\"Emfatic_class\" : ${the class name provided by Model_Checker}, ' +\n",
    "    '\"Emfatic_attributes\": ${the \"attr\"s that the class contains (if not null)}, ' +\n",
    "    '\"Emfatic_references\":${the \"ref\"s or \"val\"s that the class contains (if not null)}, ' +\n",
    "    '\"Emfatic_operations\": ${the \"op\"s that class contains (if not null)} }' +\n",
    "    'If the Emfatic code creates multiple classes, please create a JSON list with multiple JSON entries, like so: [$JSON entry, $JSON entry, ... $JSON entry].' +\n",
    "    ' The Output format is JSON only, no markdown permitted (no ```), no explain.'\n",
    "] \n",
    "    \n",
    "    for i in range(times):\n",
    "        with open(\"assets/requirement_architecture.json\", 'r', encoding='utf-8') as rq:\n",
    "            requirement_file = rq.read()\n",
    "\n",
    "        with open(f'result/DSL_extraction_result/single_DSL_extraction_result_{i+1}.emf', 'r', encoding='utf-8') as code:\n",
    "            emfatic_code = code.read()\n",
    "        \n",
    "        start = time.time()\n",
    "        model = \"gpt-4o\"\n",
    "        temperature = 0.2\n",
    "        prompt = 'This is requirement JSON:'+requirement_file+'this is the Emfatic code: '+emfatic_code\n",
    "        \n",
    "        res = get_completion(prompt, model=model, temperature=temperature, message=message)\n",
    "\n",
    "        print(f\"Iteration {i+1}:\")\n",
    "        print(f\"Time taken: {time.time() - start} seconds\")\n",
    "        print(res[0])  # gpt4的结果，看这里\n",
    "\n",
    "        with open(f'result/DSL_trace_result/single_DSL_trace_result_{i+1}.json', 'w', encoding='utf-8') as f:\n",
    "            f.write(res[0])"
   ],
   "id": "bf05a46ccd30de49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:38:58.007618Z",
     "start_time": "2024-11-07T14:38:17.324591Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_dsl_trace_extraction(times)"
   ],
   "id": "648cee92384e6495",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:38:58.014627Z",
     "start_time": "2024-11-07T14:38:58.008624Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_emf_creation(times):   \n",
    "    # Few-shot example for modeller\n",
    "    with open('assets/few_shot_example_model_creation.txt', 'r', encoding='utf-8') as f:\n",
    "        few_shot_example_model_creation = f.read()   \n",
    "    # chain of thought prompt for modeller\n",
    "    with open('assets/chain_of_thought_model_creation.txt', 'r') as f:\n",
    "        chain_of_thought_model_creation = f.read()   \n",
    "    with open(\"assets/requirement_architecture.json\", 'r', encoding='utf-8') as rq:\n",
    "        requirement_file = rq.read()       \n",
    "    for i in range(times):\n",
    "        with open(f'result/Term_extraction_result/single_term_extraction_result_{i+1}.json', 'r') as f:\n",
    "            term_extraction = f.read()\n",
    "        with open(f'result/DSL_extraction_result/single_DSL_extraction_result_{i+1}.emf', 'r', encoding='utf-8') as DSL_source:\n",
    "            dsl = DSL_source.read()\n",
    "        message = [\n",
    "            'You are an expert in Model Driven Engineering (MDE). ' +\n",
    "            'You are experienced in creating EMF (Eclipse Modelling Framework) models using the Epsilon Object Language (EOL). ' +\n",
    "            'Your job is to write an EOL program to create an EMF model that conforms to the EMF metamodel (written in the Emfatic language) in here: ' + dsl +\n",
    "            'You should base your answer on the requirements provided to you by User. ' +\n",
    "            'The Concepts extracted (in JSON) from the requirements are here: ' + term_extraction +\n",
    "            'Consult the thinking process here: ' + chain_of_thought_model_creation +\n",
    "            'Here are some examples based on input requirements:' + few_shot_example_model_creation +\n",
    "            'You should also consult the code produced by Model_Refactor. ' +\n",
    "            'You must only include EOL code in your responses. ' +\n",
    "            'Do not include any other contents that are not provided to you. ' +\n",
    "            'Please do not include explanations in your answers. Do not include markdowns (no ```). ',\n",
    "            ]\n",
    "        start = time.time()\n",
    "        model = \"gpt-4o\"\n",
    "        temperature = 0.2\n",
    "        prompt = requirement_file\n",
    "        res = get_completion(prompt, model=model, temperature=temperature, message=message)\n",
    "\n",
    "        print(f\"Iteration {i+1}:\")\n",
    "        print(f\"Time taken: {time.time() - start} seconds\")\n",
    "        print(res[0])  # gpt4的结果，看这里\n",
    "\n",
    "        with open(f'result/EMF_Model_result/single_eol_result_{i+1}.eol', 'w', encoding='utf-8') as f:\n",
    "            f.write(res[0])"
   ],
   "id": "582988b99dfcf3e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:39:38.289617Z",
     "start_time": "2024-11-07T14:38:58.015635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_emf_creation(times)"
   ],
   "id": "65a422b3d3c605b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:39:38.296092Z",
     "start_time": "2024-11-07T14:39:38.289617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_emf_trace_creation(times):\n",
    "    \n",
    "    with open('assets/chain_of_thought_model_trace.txt', 'r') as f:\n",
    "        chain_of_thought_model_trace = f.read()\n",
    "    \n",
    "    with open(\"assets/requirement_architecture.json\", 'r', encoding='utf-8') as rq:\n",
    "        requirement_file = rq.read()  \n",
    "    for i in range(times):\n",
    "        # Emfatic rules\n",
    "        with open(f'result/DSL_extraction_result/single_DSL_extraction_result_{i+1}.emf', 'r', encoding='utf-8') as DSL_source:\n",
    "            dsl = DSL_source.read()\n",
    "            \n",
    "        with open(f'result/EMF_Model_result/single_eol_result_{i+1}.eol', 'r', encoding='utf-8') as code:\n",
    "            eol_code = code.read()\n",
    "        \n",
    "        message = [\n",
    "        'You are an expert in Model Driven Engineering (MDE). ' +\n",
    "        'You are experienced in creating EMF (Eclipse Modelling Framework) models using languages provided by the Eclipse Epsilon platform. ' +\n",
    "        'Specifically, you use the Epsilon Object Language (EOL) to create EMF models programmatically. ' +\n",
    "        'Your job is to generate a JSON element by analysing the EOL code (provided by Model_Checker) for model creation, and the requirement provided by User every round. ' +\n",
    "        'The metamodel (created using the Emfatic language) for the model to be created is here: ' + dsl +\n",
    "        'Here are some guidance to help you: ' + chain_of_thought_model_trace +\n",
    "        'Your answer should be in the following JSON format : ' +\n",
    "        '{\"requirement_gid\" : ${the gid of the requirement provided by User}, ' +\n",
    "        '\"Model_Element\" : ${the name of the class created by the EOL code}, ' +\n",
    "        '\"Model_Element_id\" : ${the name or the id of the object created for the above class}, ' +\n",
    "        '\"Model_attribute\": ${the name of the attributes set by the EOL code}, ' +\n",
    "        '\"Attribute_value\": ${the value of the above attribute set by the EOL code}, ' +\n",
    "        '\"Model_references\":${the name of the references set by the EOL code} } ' +\n",
    "        '\"Reference_value\":${the name or the id of the value set for the above reference} } ' +\n",
    "        'If the EOL code creates multiple model elements, please create a JSON list with multiple JSON entries, like so: [$JSON entry, $JSON entry, ... $JSON entry].' +\n",
    "        ' The Output format is JSON only, no markdown permitted (no ```), no explain.']\n",
    "        \n",
    "        start = time.time()\n",
    "        model = \"gpt-4o\"\n",
    "        temperature = 0.2\n",
    "        prompt = 'This is requirement JSON:'+requirement_file+'this is the Emfatic code: '+eol_code\n",
    "        res = get_completion(prompt, model=model, temperature=temperature,message=message)\n",
    "        print(f\"Iteration {i+1}:\")\n",
    "        print(f\"Time taken: {time.time() - start} seconds\")\n",
    "        print(res[0])  # gpt4的结果，看这里\n",
    "        with open(f'result/EMF_Model_trace_result/single_EOL_trace_result_{i+1}.json', 'w', encoding='utf-8') as f:\n",
    "            f.write(res[0])"
   ],
   "id": "b31e4de9967c0ff0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T14:40:10.847333Z",
     "start_time": "2024-11-07T14:39:38.296092Z"
    }
   },
   "cell_type": "code",
   "source": [
    "run_emf_trace_creation(times)"
   ],
   "id": "ec01657a8cf5143",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
