{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-07T16:00:55.721043Z",
     "start_time": "2024-11-07T16:00:55.712220Z"
    }
   },
   "source": [
    "import json\n",
    "import os\n",
    "import autogen\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "class Base:\n",
    "    # set API and keyu\n",
    "    os.environ[\"OPENAI_API_BASE\"] = \"https://a.fe8.cn/v1\"\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"sk-jxGxEstKGNXlwD4gaFIIveFQOAWm7hRxUZth8k191o5m8DE4\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.groupchat = None\n",
    "        self.user = None\n",
    "        self.requirement_file = None\n",
    "        self.config_list = None\n",
    "        self.groupt_chat_manager = None\n",
    "\n",
    "    def getUser(self):\n",
    "        self.user = MyConversableAgent(\n",
    "            file_path=self.requirement_file,\n",
    "            name = \"User\",\n",
    "            llm_config = False,\n",
    "            human_input_mode='ALWAYS',\n",
    "            description='A User to provide the requirements.'\n",
    "        )\n",
    "        return self.user\n",
    "\n",
    "    def getConfigList(self):\n",
    "        self.config_list = [\n",
    "            {\n",
    "                \"model\": \"gpt-4o\",\n",
    "                \"api_key\": os.environ.get(\"OPENAI_API_KEY\"),\n",
    "                \"base_url\": os.environ.get(\"OPENAI_API_BASE\"),\n",
    "            },\n",
    "        ]\n",
    "        return self.config_list\n",
    "\n",
    "    def init_group_chat_manager(self):\n",
    "        self.groupt_chat_manager = autogen.GroupChatManager(\n",
    "            self.groupchat,\n",
    "            llm_config={\n",
    "                \"temperature\": 0.5,\n",
    "                \"config_list\": self.config_list,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def storeJSON(self, chat_results, agent_name, file_name, tag_name):\n",
    "        content = [item['content'] for item in chat_results.chat_history if item.get('name') == agent_name]\n",
    "        temp = \"{\\\"\" + tag_name+ \"\\\": []}\"\n",
    "        data = json.loads(temp)\n",
    "        with open(file_name, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "        for item in content:\n",
    "            try:\n",
    "                parsed_json = json.loads(item)\n",
    "                if type(parsed_json) is list:\n",
    "                    for sub_json in parsed_json:\n",
    "                        data[tag_name].append(sub_json)\n",
    "                else:\n",
    "                    data[tag_name].append(parsed_json)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error parsing JSON: {e}\")\n",
    "        with open(file_name, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "\n",
    "class MyConversableAgent(ConversableAgent):\n",
    "    def __init__(self, file_path, *args, **kwargs, ):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.file_path = file_path  # Path to your input file\n",
    "        self.current_index = 0  # Track the current index of req array\n",
    "        with open(self.file_path, 'r', encoding=\"utf-8\") as file:\n",
    "            self.data = json.load(file)['requirements']\n",
    "\n",
    "    def get_human_input(self, prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Override to customize the way to get human input.\n",
    "        For example, read input from a JSON file.\n",
    "        Args:\n",
    "            prompt (str): prompt for the human input.\n",
    "        Returns:\n",
    "            str: human input from a JSON file.\n",
    "        \"\"\"\n",
    "        if self.current_index < len(self.data):\n",
    "            # Get the current item from req array\n",
    "            item = self.data[self.current_index]\n",
    "            # Convert the item to string format\n",
    "            reply = json.dumps(item)\n",
    "            self.current_index += 1\n",
    "        else:\n",
    "            reply = \"exit\"  # Or any other suitable message\n",
    "        self._human_input.append(reply)\n",
    "        return reply"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:00:55.730868Z",
     "start_time": "2024-11-07T16:00:55.722058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import datetime\n",
    "\n",
    "import autogen\n",
    "from autogen import ConversableAgent\n",
    "\n",
    "\n",
    "\n",
    "class Term_Extractor(Base):\n",
    "    def __init__(self):\n",
    "        #system description\n",
    "        with open('assets/system_description.txt', 'r', encoding='utf-8') as f:\n",
    "            self.system_description = f.read()\n",
    "\n",
    "        #Few-shot example\n",
    "        with open('assets/few_shot_example_term_extraction.txt', 'r', encoding='utf-8') as I:\n",
    "            self.few_shot_example = I.read()\n",
    "\n",
    "        #chain of thought example\n",
    "        with open('assets/chain_of_thought_term_extraction.txt', 'r') as f:\n",
    "            self.chain_of_thought_term_extraction = f.read()\n",
    "\n",
    "        # chain of thought example\n",
    "        with open('assets/chain_of_thought_term_checker.txt', 'r') as f:\n",
    "            self.chain_of_thought_term_checker = f.read()\n",
    "\n",
    "        self.requirement_file = \"assets/requirement_architecture.json\"\n",
    "        self.user = super().getUser()\n",
    "\n",
    "        #term extraction agent\n",
    "        self.term_extractor = ConversableAgent(\n",
    "            name = \"Term_Extractor\",\n",
    "            llm_config={\n",
    "                \"temperature\": 0.5,\n",
    "                \"config_list\": super().getConfigList(),\n",
    "                \"timeout\": 600000,\n",
    "                \"cache_seed\": None,\n",
    "            },\n",
    "            system_message =\n",
    "            'You are an expert in requirement engineering.' +\n",
    "            'Requirement statements can be categorised into Functional Requirements and Non-Functional Requirements. ' +\n",
    "            'You will be provided with some requirement statements from User, which are for a system to be developed.' +\n",
    "            'The description of the system is here: ' + self.system_description +\n",
    "            'Your task is to extract Concepts and their Instances from the requirement statements.' +\n",
    "            'The requirements will be provided by User, please note that the requirements are not ordered, and one requirement may implicitly depend on other requirements. ' +\n",
    "            'Each requirement statement is identified by a unique GID (short for Global ID). ' +\n",
    "            'Please extract occurrences of the following from the requirement statements: \"GID\", \"Concepts\" and \"Instances\". ' +\n",
    "            'The rationale for your task is here: ' + self.chain_of_thought_term_extraction +\n",
    "            'The Output format should be in JSON only, no markdown permitted (no ```), no explain.' +\n",
    "            'Include only contents provided to you.',\n",
    "            description=\"An Term_Extractor to extract instances of a sentence.\"\n",
    "        )\n",
    "        #Term JSON checker\n",
    "        self.term_checker = ConversableAgent(\n",
    "            name=\"Term_checker\",\n",
    "            llm_config={\n",
    "                \"temperature\": 0.5,\n",
    "                \"config_list\": super().getConfigList(),\n",
    "                \"timeout\": 600000,\n",
    "                \"cache_seed\": None,\n",
    "            },\n",
    "           # llm_config=llm_default_config,\n",
    "            system_message=\n",
    "            'You are an expert in requirement engineering and Model Driven Engineering (MDE). ' +\n",
    "            'In MDE, engineers produce \"Domain Specific Models (DSLs)\" or \"metamodels\". ' +\n",
    "            'A metamodel defines the abstract syntax of a modelling language, which may contain: 1) Classes to describe the concepts in the target system (to be developed); ' +\n",
    "            '2) Attributes with primitive types inside the Classes; and 3) References (either association or containment) among Classes. ' +\n",
    "            'Each concept defined in a metamodel is also referred to as a \"meta-element\". ' +\n",
    "            'Once a metamodel is in place, engineers can use it to create \"instance models\" to model their systems, which conform to the abstract syntax defined in the metamodel. ' +\n",
    "            'Each instance of a \"meta-element\" in the instance model may also be referred to as an \"instance object\" of that \"meta-element\". ' +\n",
    "            'In order to extract DSLs, one need to make sure the Concepts and their Instances are correctly extracted. ' +\n",
    "            'Your task is to check whether the Concepts and Instances extracted by Term_Extractor are correct. ' +\n",
    "            'To provide you with context, the description of the system to be developed is here: ' + self.system_description +\n",
    "            'The rationale for your task is here: ' + self.chain_of_thought_term_checker +\n",
    "            'Here are some examples of the extracted models, which may help you.' + self.few_shot_example +\n",
    "            'The Output format should be in JSON only, no markdown permitted (no ```), no explain.' +\n",
    "            'Include only contents provided to you and Term_Extractor.',\n",
    "            description=\"A Term_checker to check the Output format from Term_Extractor.\"\n",
    "        )\n",
    "\n",
    "        self.groupchat = autogen.GroupChat(\n",
    "            agents=[self.user, self.term_extractor, self.term_checker],\n",
    "            messages=[],\n",
    "            speaker_selection_method='round_robin',\n",
    "            max_round=100,\n",
    "            send_introductions=True\n",
    "        )\n",
    "\n",
    "        super().init_group_chat_manager()\n",
    "\n",
    "    def run_extraction_multiple_times(self, times):\n",
    "        for i in range(times):\n",
    "            term_extractor = Term_Extractor()\n",
    "\n",
    "            chat_results = term_extractor.user.initiate_chat(\n",
    "                term_extractor.groupt_chat_manager,\n",
    "                # modify here to start your chat\n",
    "                message=\"\",\n",
    "                clear_history=True,\n",
    "            )\n",
    "            result_file = f\"result/Term_extraction_result/result_term_extractor_{i + 1}.json\"\n",
    "            term_extractor.storeJSON(chat_results, \"Term_checker\", result_file,\"term_trace\")"
   ],
   "id": "57d78aba323b3114",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import datetime\\n\\nimport autogen\\nfrom autogen import ConversableAgent\\n\\n\\n\\nclass Term_Extractor(Base):\\n    def __init__(self):\\n        #system description\\n        with open(\\'assets/system_description.txt\\', \\'r\\', encoding=\\'utf-8\\') as f:\\n            self.system_description = f.read()\\n\\n        #Few-shot example\\n        with open(\\'assets/few_shot_example_term_extraction.txt\\', \\'r\\', encoding=\\'utf-8\\') as I:\\n            self.few_shot_example = I.read()\\n\\n        #chain of thought example\\n        with open(\\'assets/chain_of_thought_term_extraction.txt\\', \\'r\\') as f:\\n            self.chain_of_thought_term_extraction = f.read()\\n\\n        # chain of thought example\\n        with open(\\'assets/chain_of_thought_term_checker.txt\\', \\'r\\') as f:\\n            self.chain_of_thought_term_checker = f.read()\\n\\n        self.requirement_file = \"assets/requirement_architecture.json\"\\n        self.user = super().getUser()\\n\\n        #term extraction agent\\n        self.term_extractor = ConversableAgent(\\n            name = \"Term_Extractor\",\\n            llm_config={\\n                \"temperature\": 0.5,\\n                \"config_list\": super().getConfigList(),\\n                \"timeout\": 600000,\\n                \"cache_seed\": None,\\n            },\\n            system_message =\\n            \\'You are an expert in requirement engineering.\\' +\\n            \\'Requirement statements can be categorised into Functional Requirements and Non-Functional Requirements. \\' +\\n            \\'You will be provided with some requirement statements from User, which are for a system to be developed.\\' +\\n            \\'The description of the system is here: \\' + self.system_description +\\n            \\'Your task is to extract Concepts and their Instances from the requirement statements.\\' +\\n            \\'The requirements will be provided by User, please note that the requirements are not ordered, and one requirement may implicitly depend on other requirements. \\' +\\n            \\'Each requirement statement is identified by a unique GID (short for Global ID). \\' +\\n            \\'Please extract occurrences of the following from the requirement statements: \"GID\", \"Concepts\" and \"Instances\". \\' +\\n            \\'The rationale for your task is here: \\' + self.chain_of_thought_term_extraction +\\n            \\'The Output format should be in JSON only, no markdown permitted (no ```), no explain.\\' +\\n            \\'Include only contents provided to you.\\',\\n            description=\"An Term_Extractor to extract instances of a sentence.\"\\n        )\\n        #Term JSON checker\\n        self.term_checker = ConversableAgent(\\n            name=\"Term_checker\",\\n            llm_config={\\n                \"temperature\": 0.5,\\n                \"config_list\": super().getConfigList(),\\n                \"timeout\": 600000,\\n                \"cache_seed\": None,\\n            },\\n           # llm_config=llm_default_config,\\n            system_message=\\n            \\'You are an expert in requirement engineering and Model Driven Engineering (MDE). \\' +\\n            \\'In MDE, engineers produce \"Domain Specific Models (DSLs)\" or \"metamodels\". \\' +\\n            \\'A metamodel defines the abstract syntax of a modelling language, which may contain: 1) Classes to describe the concepts in the target system (to be developed); \\' +\\n            \\'2) Attributes with primitive types inside the Classes; and 3) References (either association or containment) among Classes. \\' +\\n            \\'Each concept defined in a metamodel is also referred to as a \"meta-element\". \\' +\\n            \\'Once a metamodel is in place, engineers can use it to create \"instance models\" to model their systems, which conform to the abstract syntax defined in the metamodel. \\' +\\n            \\'Each instance of a \"meta-element\" in the instance model may also be referred to as an \"instance object\" of that \"meta-element\". \\' +\\n            \\'In order to extract DSLs, one need to make sure the Concepts and their Instances are correctly extracted. \\' +\\n            \\'Your task is to check whether the Concepts and Instances extracted by Term_Extractor are correct. \\' +\\n            \\'To provide you with context, the description of the system to be developed is here: \\' + self.system_description +\\n            \\'The rationale for your task is here: \\' + self.chain_of_thought_term_checker +\\n            \\'Here are some examples of the extracted models, which may help you.\\' + self.few_shot_example +\\n            \\'The Output format should be in JSON only, no markdown permitted (no ```), no explain.\\' +\\n            \\'Include only contents provided to you and Term_Extractor.\\',\\n            description=\"A Term_checker to check the Output format from Term_Extractor.\"\\n        )\\n\\n        self.groupchat = autogen.GroupChat(\\n            agents=[self.user, self.term_extractor, self.term_checker],\\n            messages=[],\\n            speaker_selection_method=\\'round_robin\\',\\n            max_round=100,\\n            send_introductions=True\\n        )\\n\\n        super().init_group_chat_manager()\\n\\n    def run_extraction_multiple_times(self, times):\\n        for i in range(times):\\n            term_extractor = Term_Extractor()\\n\\n            chat_results = term_extractor.user.initiate_chat(\\n                term_extractor.groupt_chat_manager,\\n                # modify here to start your chat\\n                message=\"\",\\n                clear_history=True,\\n            )\\n            result_file = f\"result/Term_extraction_result/result_term_extractor_{i + 1}.json\"\\n            term_extractor.storeJSON(chat_results, \"Term_checker\", result_file,\"term_trace\")'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:00:55.748087Z",
     "start_time": "2024-11-07T16:00:55.744569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Term_Extractor().run_extraction_multiple_times(2)"
   ],
   "id": "495194195441905e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Term_Extractor().run_extraction_multiple_times(2)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:00:55.784081Z",
     "start_time": "2024-11-07T16:00:55.776085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DSL_Extractor(Base): \n",
    "    def run_dsl_extraction(times):\n",
    "        for i in range(times):    \n",
    "                def __init__(self):\n",
    "                    #system description\n",
    "                    with open('assets/system_description.txt', 'r', encoding='utf-8') as system_file:\n",
    "                        system_description = system_file.read()\n",
    "            \n",
    "                    #Few-shot example for dsl extraction\n",
    "                    with open('assets/few_shot_example_dsl_extraction.txt', 'r', encoding='utf-8') as few_shot_dsl_file:\n",
    "                        few_shot_example_dsl_extraction = few_shot_dsl_file.read()\n",
    "            \n",
    "                    #Few-shot example for dsl checker\n",
    "                    with open('assets/few_shot_example_dsl_checker.txt', 'r', encoding='utf-8') as few_shot_dsl_checker:\n",
    "                        few_shot_example_dsl_checker = few_shot_dsl_checker.read()\n",
    "            \n",
    "                    #chain of thought prompt for dsl extraction\n",
    "                    with open('assets/chain_of_thought_dsl_extraction.txt', 'r') as cot_dsl_extraction:\n",
    "                        chain_of_thought_dsl_extraction = cot_dsl_extraction.read()\n",
    "            \n",
    "                    #chain of thought prompt for dsl checker\n",
    "                    with open('assets/chain_of_thought_dsl_checker.txt', 'r') as cot_dsl_checker:\n",
    "                        chain_of_thought_dsl_checker = cot_dsl_checker.read()\n",
    "            \n",
    "                    #Extracted terms\n",
    "                    with open(f\"result/Term_extraction_result/result_term_extractor_{i + 1}.json\", 'r', encoding='utf-8') as term_file:\n",
    "                        extracted_terms = term_file.read()\n",
    "            \n",
    "                    #Emfatic rules\n",
    "                    with open('assets/emfatic.txt', 'r', encoding='utf-8') as emfatic_rules_file:\n",
    "                        emfatic_rules = emfatic_rules_file.read()\n",
    "            \n",
    "                    self.requirement_file = \"assets/requirement_architecture.json\"\n",
    "                    self.user = super().getUser()\n",
    "            \n",
    "                    #DSL Extractor to create emfatic code\n",
    "                    self.dsl_extractor = ConversableAgent(\n",
    "                        name=\"DSL_Extractor\",\n",
    "                        llm_config={\n",
    "                            \"temperature\": 0.5,\n",
    "                            \"config_list\": super().getConfigList(),\n",
    "                            \"timeout\": 600000,\n",
    "                            \"cache_seed\": None,\n",
    "                        },\n",
    "                        system_message=\n",
    "                        'You are an expert in Model Driven Engineering (MDE). ' +\n",
    "                        'You are experienced in creating \"Domain Specific Languages (DSLs)\" or \"metamodels\". ' +\n",
    "                        'A metamodel contains the abstract syntax to capture the concepts for the system to be developed. ' +\n",
    "                        'You have extensive experience in creating metamodels using the Ecore modeling language provided by the Eclipse Modeling Framework (EMF). ' +\n",
    "                        'You are also an expert in creating metamodels using the Emfatic language (a textual syntax for Ecore) to create metamodels.' +\n",
    "                        'Your job is to create a metamodel written in Emfatic based on the requirements provided to you in JSON every round. ' +\n",
    "                        'The description of the system to be developed is here: ' + system_description +\n",
    "                        'Previously, a Term model is extracted, in here: ' + extracted_terms +\n",
    "                        'Here are some thinking processes to guide you: ' + chain_of_thought_dsl_extraction +\n",
    "                        'Here are some examples of the extracted metamodels based on inputs:' + few_shot_example_dsl_extraction +\n",
    "                        'Consider also the previous inputs from the User. ' +\n",
    "                        'You must only include Emfatic code in your responses.' +\n",
    "                        'Do not include any other contents that are not provided to you. ' +\n",
    "                        'Please do not include explanations in your answers. In addition, no markdown is permitted (no ```). ',\n",
    "                        description='A DSL extractor to create metamodels using Emfatic based on the input and responses from the User.'\n",
    "                    )\n",
    "            \n",
    "                    #DSL checker to check the syntax of Emfatic code\n",
    "                    self.dsl_checker = ConversableAgent(\n",
    "                        name=\"DSL_Checker\",\n",
    "                        llm_config={\n",
    "                            \"temperature\": 0.5,\n",
    "                            \"config_list\": super().getConfigList(),\n",
    "                            \"timeout\": 600000,\n",
    "                            \"cache_seed\": None,\n",
    "                        },\n",
    "                        system_message=\n",
    "                        'You are an expert in Model Driven Engineering (MDE). ' +\n",
    "                        'Specifically, you are experienced in create \"Domain Specific Languages (DSLs)\" or \"metamodels\". ' +\n",
    "                        'A metamodel contains the abstract syntax to capture the concepts for the system to be developed. ' +\n",
    "                        'You have extensive experience in creating metamodels using the Ecore modeling language provided by the Eclipse Modeling Framework (EMF). '\n",
    "                        'You are also an expert in using the Emfatic language (a textual syntax for Ecore) to create metamodels. ' +\n",
    "                        'An description of the language syntax for Emfatic is here: ' + emfatic_rules +\n",
    "                        'Your job is to check whether the metamodel provided to you written in Emfatic is correct, in every round of conversation. ' +\n",
    "                        'You should also consult the thinking process in here: ' + chain_of_thought_dsl_checker +\n",
    "                        'Here are some examples of the extracted metamodels based on inputs:' + few_shot_example_dsl_checker +\n",
    "                        'You should also consult the terms extracted previously (but do not rely on it completely): ' + extracted_terms +\n",
    "                        'You must only include Emfatic code in your responses.' +\n",
    "                        'Do not include any other contents that are not provided to you. ' +\n",
    "                        'Please do not include explanations in your answers. In addition, no markdown is permitted (no ```). ',\n",
    "                        description='A Model_Checker to check the syntax of Emfatic code.'\n",
    "                    )\n",
    "            \n",
    "                    #DSL refactor to summerize the code from Model_Checker&Modeller\n",
    "                    self.dsl_refactorer = ConversableAgent(\n",
    "                        name=\"DSL_Refactor\",\n",
    "                        llm_config={\n",
    "                            \"temperature\": 0.5,\n",
    "                            \"config_list\": super().getConfigList(),\n",
    "                            \"timeout\": 600000,\n",
    "                            \"cache_seed\": None,\n",
    "                        },\n",
    "                        system_message=\n",
    "                        'You are an expert in Model Driven Engineering (MDE), and you are working with some experts in creating \"Domain Specific Languages (DSLs)\" or \"metamodels\". ' +\n",
    "                        'DSL_Extractor has created the DSL using Emfatic based on the inputs from User. ' +\n",
    "                        'Model_Checker has checked the syntax of the Emfatic code. ' +\n",
    "                        'Your job is to organise and refactor (when necessary) the Emfatic code provided by Model_Checker. ' +\n",
    "                        'In every round, you provide your answer, you need to combine with your previous answer and update them in one package. ' +\n",
    "                        'Pay attention to containement and non-containment references. ' +\n",
    "                        'In the requirement, when it says \"A contains B\" or \"A defines B\", it often denotes a containment reference. ' +\n",
    "                        'In the requirement, when it says \"A uses B\" or \"A refers to B\", it often denotes a non-containment reference. ' +\n",
    "                        'Refactor references when necessary by looking at the requirements as a whole. ' +\n",
    "                        'Your answer needs to be correctly written in Emfatic. ' +\n",
    "                        'You must include only Emfatic code in your responses.' +\n",
    "                        'Do not include any other contents that are not provided to you. ' +\n",
    "                        'Please do not explain. In addition, no markdown is permitted (no ```)',\n",
    "                        description='A DSL_Refactor to organise and refactor the code from Model_Checker.'\n",
    "                    )\n",
    "            \n",
    "                    #Json_Generator to generate a json for traceability.\n",
    "                    self.json_generator = ConversableAgent(\n",
    "                        name=\"Json_Generator\",\n",
    "                        llm_config={\n",
    "                            \"temperature\": 0.5,\n",
    "                            \"config_list\": super().getConfigList(),\n",
    "                            \"timeout\": 600000,\n",
    "                            \"cache_seed\": None,\n",
    "                        },\n",
    "                        system_message=\n",
    "                        'You are an expert in Model Driven Engineering (MDE). ' +\n",
    "                        'Your job is to generate a traceability JSON element based on the Emfatic code provided by DSL_Summariser and the requirement in JSON provided by User every round. ' +\n",
    "                        'In the Emfatic code provided to you by DSL_Summariser, you shall identify which class, attributes, references and operations are created, based on the requirement JSON provided by User' +\n",
    "                        'Your answer should be in the following JSON format : ' +\n",
    "                        '{\"requirement_gid\" : ${the gid of the requirement provided by User}, ' +\n",
    "                        '\"Emfatic_class\" : ${the class name provided by Model_Checker}, ' +\n",
    "                        '\"Emfatic_attributes\": ${the \"attr\"s that the class contains (if not null)}, ' +\n",
    "                        '\"Emfatic_references\":${the \"ref\"s or \"val\"s that the class contains (if not null)}, ' +\n",
    "                        '\"Emfatic_operations\": ${the \"op\"s that class contains (if not null)} }' +\n",
    "                        'If the Emfatic code creates multiple classes, please create a JSON list with multiple JSON entries, like so: [$JSON entry, $JSON entry, ... $JSON entry].' +\n",
    "                        ' The Output format is JSON only, no markdown permitted (no ```), no explain.',\n",
    "                        description='A Json_Generator to generate a json element based on the Emfatic code provided by Model Checker and the requirement provided by User every round.'\n",
    "                    )\n",
    "            \n",
    "                    #Create a groupchat to organise the agents\n",
    "                    self.groupchat = autogen.GroupChat(\n",
    "                        agents=[self.user, self.dsl_extractor, self.dsl_checker, self.dsl_refactorer, self.json_generator],\n",
    "                        messages=[],\n",
    "                        speaker_selection_method='round_robin',\n",
    "                        max_round=500,\n",
    "                        send_introductions=True\n",
    "                    )\n",
    "            \n",
    "                    super().init_group_chat_manager()\n",
    "                    dsl_extractor = DSL_Extractor()\n",
    "                    chat_results = dsl_extractor.user.initiate_chat(\n",
    "                        dsl_extractor.groupt_chat_manager,\n",
    "                        # message=\"Let us start extracting Domain Specific Languages (DSL) or metamodels from the requirements in JSON. \" +\n",
    "                        # \"DSL_Extractor will extract the DSL, DSL_Checker will check the correctness of the DSL, DSL_Refactor will organise and refactor the DSL. \" +\n",
    "                        # \"The JSON_Generator will generate the JSON file containing trace information.\",\n",
    "                        clear_history=True,\n",
    "                    )\n",
    "        \n",
    "                    dsl_extractor.storeJSON(chat_results, \"Json_Generator\", f\"result/DSL_trace_result/multi_dsl_trace_result_{i+1}.json\", \"dsl_trace\")\n",
    "        \n",
    "                    data = chat_results.chat_history\n",
    "        \n",
    "                    # Extract the last content for 'DSL_Refactor'\n",
    "                    last_dsl_refactor_content = next(\n",
    "                        (entry['content'] for entry in reversed(data) if entry.get('name') == 'DSL_Refactor'), None)\n",
    "        \n",
    "                    if last_dsl_refactor_content:\n",
    "                        with open(f'result/DSL_extraction_result/multi_DSL_extraction_result_{i+1}.emf', 'w', encoding='utf-8') as file:\n",
    "                            file.write(last_dsl_refactor_content)\n",
    "        \n",
    "                    # Print the last content\n",
    "                    print(last_dsl_refactor_content)\n"
   ],
   "id": "295b133a06c275a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'class DSL_Extractor(Base): \\n    def run_dsl_extraction(times):\\n        for i in range(times):    \\n                def __init__(self):\\n                    #system description\\n                    with open(\\'assets/system_description.txt\\', \\'r\\', encoding=\\'utf-8\\') as system_file:\\n                        system_description = system_file.read()\\n            \\n                    #Few-shot example for dsl extraction\\n                    with open(\\'assets/few_shot_example_dsl_extraction.txt\\', \\'r\\', encoding=\\'utf-8\\') as few_shot_dsl_file:\\n                        few_shot_example_dsl_extraction = few_shot_dsl_file.read()\\n            \\n                    #Few-shot example for dsl checker\\n                    with open(\\'assets/few_shot_example_dsl_checker.txt\\', \\'r\\', encoding=\\'utf-8\\') as few_shot_dsl_checker:\\n                        few_shot_example_dsl_checker = few_shot_dsl_checker.read()\\n            \\n                    #chain of thought prompt for dsl extraction\\n                    with open(\\'assets/chain_of_thought_dsl_extraction.txt\\', \\'r\\') as cot_dsl_extraction:\\n                        chain_of_thought_dsl_extraction = cot_dsl_extraction.read()\\n            \\n                    #chain of thought prompt for dsl checker\\n                    with open(\\'assets/chain_of_thought_dsl_checker.txt\\', \\'r\\') as cot_dsl_checker:\\n                        chain_of_thought_dsl_checker = cot_dsl_checker.read()\\n            \\n                    #Extracted terms\\n                    with open(f\"result/Term_extraction_result/result_term_extractor_{i + 1}.json\", \\'r\\', encoding=\\'utf-8\\') as term_file:\\n                        extracted_terms = term_file.read()\\n            \\n                    #Emfatic rules\\n                    with open(\\'assets/emfatic.txt\\', \\'r\\', encoding=\\'utf-8\\') as emfatic_rules_file:\\n                        emfatic_rules = emfatic_rules_file.read()\\n            \\n                    self.requirement_file = \"assets/requirement_architecture.json\"\\n                    self.user = super().getUser()\\n            \\n                    #DSL Extractor to create emfatic code\\n                    self.dsl_extractor = ConversableAgent(\\n                        name=\"DSL_Extractor\",\\n                        llm_config={\\n                            \"temperature\": 0.5,\\n                            \"config_list\": super().getConfigList(),\\n                            \"timeout\": 600000,\\n                            \"cache_seed\": None,\\n                        },\\n                        system_message=\\n                        \\'You are an expert in Model Driven Engineering (MDE). \\' +\\n                        \\'You are experienced in creating \"Domain Specific Languages (DSLs)\" or \"metamodels\". \\' +\\n                        \\'A metamodel contains the abstract syntax to capture the concepts for the system to be developed. \\' +\\n                        \\'You have extensive experience in creating metamodels using the Ecore modeling language provided by the Eclipse Modeling Framework (EMF). \\' +\\n                        \\'You are also an expert in creating metamodels using the Emfatic language (a textual syntax for Ecore) to create metamodels.\\' +\\n                        \\'Your job is to create a metamodel written in Emfatic based on the requirements provided to you in JSON every round. \\' +\\n                        \\'The description of the system to be developed is here: \\' + system_description +\\n                        \\'Previously, a Term model is extracted, in here: \\' + extracted_terms +\\n                        \\'Here are some thinking processes to guide you: \\' + chain_of_thought_dsl_extraction +\\n                        \\'Here are some examples of the extracted metamodels based on inputs:\\' + few_shot_example_dsl_extraction +\\n                        \\'Consider also the previous inputs from the User. \\' +\\n                        \\'You must only include Emfatic code in your responses.\\' +\\n                        \\'Do not include any other contents that are not provided to you. \\' +\\n                        \\'Please do not include explanations in your answers. In addition, no markdown is permitted (no ```). \\',\\n                        description=\\'A DSL extractor to create metamodels using Emfatic based on the input and responses from the User.\\'\\n                    )\\n            \\n                    #DSL checker to check the syntax of Emfatic code\\n                    self.dsl_checker = ConversableAgent(\\n                        name=\"DSL_Checker\",\\n                        llm_config={\\n                            \"temperature\": 0.5,\\n                            \"config_list\": super().getConfigList(),\\n                            \"timeout\": 600000,\\n                            \"cache_seed\": None,\\n                        },\\n                        system_message=\\n                        \\'You are an expert in Model Driven Engineering (MDE). \\' +\\n                        \\'Specifically, you are experienced in create \"Domain Specific Languages (DSLs)\" or \"metamodels\". \\' +\\n                        \\'A metamodel contains the abstract syntax to capture the concepts for the system to be developed. \\' +\\n                        \\'You have extensive experience in creating metamodels using the Ecore modeling language provided by the Eclipse Modeling Framework (EMF). \\'\\n                        \\'You are also an expert in using the Emfatic language (a textual syntax for Ecore) to create metamodels. \\' +\\n                        \\'An description of the language syntax for Emfatic is here: \\' + emfatic_rules +\\n                        \\'Your job is to check whether the metamodel provided to you written in Emfatic is correct, in every round of conversation. \\' +\\n                        \\'You should also consult the thinking process in here: \\' + chain_of_thought_dsl_checker +\\n                        \\'Here are some examples of the extracted metamodels based on inputs:\\' + few_shot_example_dsl_checker +\\n                        \\'You should also consult the terms extracted previously (but do not rely on it completely): \\' + extracted_terms +\\n                        \\'You must only include Emfatic code in your responses.\\' +\\n                        \\'Do not include any other contents that are not provided to you. \\' +\\n                        \\'Please do not include explanations in your answers. In addition, no markdown is permitted (no ```). \\',\\n                        description=\\'A Model_Checker to check the syntax of Emfatic code.\\'\\n                    )\\n            \\n                    #DSL refactor to summerize the code from Model_Checker&Modeller\\n                    self.dsl_refactorer = ConversableAgent(\\n                        name=\"DSL_Refactor\",\\n                        llm_config={\\n                            \"temperature\": 0.5,\\n                            \"config_list\": super().getConfigList(),\\n                            \"timeout\": 600000,\\n                            \"cache_seed\": None,\\n                        },\\n                        system_message=\\n                        \\'You are an expert in Model Driven Engineering (MDE), and you are working with some experts in creating \"Domain Specific Languages (DSLs)\" or \"metamodels\". \\' +\\n                        \\'DSL_Extractor has created the DSL using Emfatic based on the inputs from User. \\' +\\n                        \\'Model_Checker has checked the syntax of the Emfatic code. \\' +\\n                        \\'Your job is to organise and refactor (when necessary) the Emfatic code provided by Model_Checker. \\' +\\n                        \\'In every round, you provide your answer, you need to combine with your previous answer and update them in one package. \\' +\\n                        \\'Pay attention to containement and non-containment references. \\' +\\n                        \\'In the requirement, when it says \"A contains B\" or \"A defines B\", it often denotes a containment reference. \\' +\\n                        \\'In the requirement, when it says \"A uses B\" or \"A refers to B\", it often denotes a non-containment reference. \\' +\\n                        \\'Refactor references when necessary by looking at the requirements as a whole. \\' +\\n                        \\'Your answer needs to be correctly written in Emfatic. \\' +\\n                        \\'You must include only Emfatic code in your responses.\\' +\\n                        \\'Do not include any other contents that are not provided to you. \\' +\\n                        \\'Please do not explain. In addition, no markdown is permitted (no ```)\\',\\n                        description=\\'A DSL_Refactor to organise and refactor the code from Model_Checker.\\'\\n                    )\\n            \\n                    #Json_Generator to generate a json for traceability.\\n                    self.json_generator = ConversableAgent(\\n                        name=\"Json_Generator\",\\n                        llm_config={\\n                            \"temperature\": 0.5,\\n                            \"config_list\": super().getConfigList(),\\n                            \"timeout\": 600000,\\n                            \"cache_seed\": None,\\n                        },\\n                        system_message=\\n                        \\'You are an expert in Model Driven Engineering (MDE). \\' +\\n                        \\'Your job is to generate a traceability JSON element based on the Emfatic code provided by DSL_Summariser and the requirement in JSON provided by User every round. \\' +\\n                        \\'In the Emfatic code provided to you by DSL_Summariser, you shall identify which class, attributes, references and operations are created, based on the requirement JSON provided by User\\' +\\n                        \\'Your answer should be in the following JSON format : \\' +\\n                        \\'{\"requirement_gid\" : ${the gid of the requirement provided by User}, \\' +\\n                        \\'\"Emfatic_class\" : ${the class name provided by Model_Checker}, \\' +\\n                        \\'\"Emfatic_attributes\": ${the \"attr\"s that the class contains (if not null)}, \\' +\\n                        \\'\"Emfatic_references\":${the \"ref\"s or \"val\"s that the class contains (if not null)}, \\' +\\n                        \\'\"Emfatic_operations\": ${the \"op\"s that class contains (if not null)} }\\' +\\n                        \\'If the Emfatic code creates multiple classes, please create a JSON list with multiple JSON entries, like so: [$JSON entry, $JSON entry, ... $JSON entry].\\' +\\n                        \\' The Output format is JSON only, no markdown permitted (no ```), no explain.\\',\\n                        description=\\'A Json_Generator to generate a json element based on the Emfatic code provided by Model Checker and the requirement provided by User every round.\\'\\n                    )\\n            \\n                    #Create a groupchat to organise the agents\\n                    self.groupchat = autogen.GroupChat(\\n                        agents=[self.user, self.dsl_extractor, self.dsl_checker, self.dsl_refactorer, self.json_generator],\\n                        messages=[],\\n                        speaker_selection_method=\\'round_robin\\',\\n                        max_round=500,\\n                        send_introductions=True\\n                    )\\n            \\n                    super().init_group_chat_manager()\\n                    dsl_extractor = DSL_Extractor()\\n                    chat_results = dsl_extractor.user.initiate_chat(\\n                        dsl_extractor.groupt_chat_manager,\\n                        # message=\"Let us start extracting Domain Specific Languages (DSL) or metamodels from the requirements in JSON. \" +\\n                        # \"DSL_Extractor will extract the DSL, DSL_Checker will check the correctness of the DSL, DSL_Refactor will organise and refactor the DSL. \" +\\n                        # \"The JSON_Generator will generate the JSON file containing trace information.\",\\n                        clear_history=True,\\n                    )\\n        \\n                    dsl_extractor.storeJSON(chat_results, \"Json_Generator\", f\"result/DSL_trace_result/multi_dsl_trace_result_{i+1}.json\", \"dsl_trace\")\\n        \\n                    data = chat_results.chat_history\\n        \\n                    # Extract the last content for \\'DSL_Refactor\\'\\n                    last_dsl_refactor_content = next(\\n                        (entry[\\'content\\'] for entry in reversed(data) if entry.get(\\'name\\') == \\'DSL_Refactor\\'), None)\\n        \\n                    if last_dsl_refactor_content:\\n                        with open(f\\'result/DSL_extraction_result/multi_DSL_extraction_result_{i+1}.emf\\', \\'w\\', encoding=\\'utf-8\\') as file:\\n                            file.write(last_dsl_refactor_content)\\n        \\n                    # Print the last content\\n                    print(last_dsl_refactor_content)'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T16:00:56.992016Z",
     "start_time": "2024-11-07T16:00:56.992016Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def EMF_Model_Creation(times):\n",
    "    for i in range(times):\n",
    "        class Model_Creator(Base):\n",
    "            def __init__(self,i):\n",
    "                #system description\n",
    "                with open('assets/system_description.txt', 'r', encoding='utf-8') as f:\n",
    "                    system_description = f.read()\n",
    "        \n",
    "                #Few-shot example for modeller\n",
    "                with open('assets/few_shot_example_model_creation.txt', 'r', encoding='utf-8') as f:\n",
    "                    few_shot_example_model_creation = f.read()\n",
    "        \n",
    "                #Few-shot example for model checker\n",
    "                with open('assets/few_shot_example_model_checker.txt', 'r', encoding='utf-8') as f:\n",
    "                    few_shot_example_model_checker = f.read()\n",
    "        \n",
    "                #chain of thought prompt for modeller\n",
    "                with open('assets/chain_of_thought_model_creation.txt', 'r') as f:\n",
    "                    chain_of_thought_model_creation = f.read()\n",
    "        \n",
    "                #chain of thought prompt for model checker\n",
    "                with open('assets/chain_of_thought_model_checker.txt', 'r') as f:\n",
    "                    chain_of_thought_model_checker = f.read()\n",
    "        \n",
    "                #chain of thought prompt for model checker\n",
    "                with open('assets/chain_of_thought_model_trace.txt', 'r') as f:\n",
    "                    chain_of_thought_model_trace = f.read()\n",
    "        \n",
    "                #chain of thought prompt for model checker\n",
    "                with open(f\"result/Term_extraction_result/result_term_extractor_{i + 1}.json\", 'r') as f:\n",
    "                    term_extraction = f.read()\n",
    "        \n",
    "                #Emfatic rules\n",
    "                with open(f'result/DSL_extraction_result/multi_DSL_extraction_result_{i+1}.emf', 'r', encoding='utf-8') as DSL_source:\n",
    "                    dsl = DSL_source.read()\n",
    "        \n",
    "                self.requirement_file = \"assets/requirement_architecture.json\"\n",
    "                self.user = super().getUser()\n",
    "        \n",
    "                #Modeller to create emfatic code\n",
    "                self.model_Creator = ConversableAgent(\n",
    "                    name=\"Model_Creator\",\n",
    "                    llm_config={\n",
    "                        \"temperature\": 0.5,\n",
    "                        \"config_list\": super().getConfigList(),\n",
    "                        \"timeout\": 600000,\n",
    "                        \"cache_seed\": None,\n",
    "                    },\n",
    "                    system_message=\n",
    "                    'You are an expert in Model Driven Engineering (MDE). ' +\n",
    "                    'You are experienced in creating EMF (Eclipse Modelling Framework) models using the Epsilon Object Language (EOL). ' +\n",
    "                    'Your job is to write an EOL program to create an EMF model that conforms to the EMF metamodel (written in the Emfatic language) in here: ' + dsl +\n",
    "                    'You should base your answer on the requirements provided to you by User. ' +\n",
    "                    #'The description of the system to be developed is here: ' + system_description +\n",
    "                    'The Concepts extracted (in JSON) from the requirements are here: ' + term_extraction +\n",
    "                    'Consult the thinking process here: ' + chain_of_thought_model_creation +\n",
    "                    'Here are some examples based on input requirements:' + few_shot_example_model_creation +\n",
    "                    'You should also consult the code produced by Model_Refactor. ' +\n",
    "                    'You must only include EOL code in your responses. ' +\n",
    "                    'Do not include any other contents that are not provided to you. ' +\n",
    "                    'Please do not include explanations in your answers. Do not include markdowns (no ```). ',\n",
    "                    description='A EMF model creator using EOL, based on the inputs and responses from the User.'\n",
    "                )\n",
    "        \n",
    "                #Model_Checker to check the syntax of Emfatic code\n",
    "                self.model_Checker = ConversableAgent(\n",
    "                    name=\"Model_Checker\",\n",
    "                    llm_config={\n",
    "                        \"temperature\": 0.5,\n",
    "                        \"config_list\": super().getConfigList(),\n",
    "                        \"timeout\": 600000,\n",
    "                        \"cache_seed\": None,\n",
    "                    },\n",
    "                    system_message=\n",
    "                    'You are an expert in Model Driven Engineering (MDE). ' +\n",
    "                    'You are experienced in creating EMF (Eclipse Modelling Framework) models using the Epsilon Object Language (EOL). ' +\n",
    "                    'Your job is to check if the EOL program provided to you is correct, and respond with the correct EOL code.' +\n",
    "                    'You should base your answer on both the EMF metamodel (written in Emfatic) here:'  + dsl +\n",
    "                    ', and the requirements provided by User. ' +\n",
    "                    'The description of the system to be developed is here: ' + system_description +\n",
    "                    'The Concepts extracted (in JSON) from the requirements are here: ' + term_extraction +\n",
    "                    'Consult the thinking process in here: ' + chain_of_thought_model_checker +\n",
    "                    'Here are some examples of the extracted metamodels based on inputs:' + few_shot_example_model_checker +\n",
    "                    #'You should also consult the code produced by Model_Refactor. ' +\n",
    "                    'You must only include EOL code in your responses.' +\n",
    "                    'Do not include any other contents that are not provided to you. ' +\n",
    "                    #'If no further answer can be provided, repeat your last answer. ' +\n",
    "                    'Please do not include explanations in your answers. In addition, no markdown is permitted (no ```). ',\n",
    "                    description='A program checker to check the syntax of the EOL code.'\n",
    "                )\n",
    "        \n",
    "                #Model_Summerizer to summerize the code from Model_Checker&Modeller\n",
    "                self.model_Refactorer = ConversableAgent(\n",
    "                    name=\"Model_Refactorer\",\n",
    "                    llm_config={\n",
    "                        \"temperature\": 0.5,\n",
    "                        \"config_list\": super().getConfigList(),\n",
    "                        \"timeout\": 600000,\n",
    "                        \"cache_seed\": None,\n",
    "                    },\n",
    "                    system_message=\n",
    "                    'You are an expert in Model Driven Engineering (MDE), and you are working with some experts in creating models that conform to a metamodel written in the Emfatic language. ' +\n",
    "                    'Model_Creator has created the source code in Epsilon Object Language (EOL) based on the inputs from User. ' +\n",
    "                    'Model_Checker has checked the syntax of the EOL code. ' +\n",
    "                    'Your job is to organise and refactor the EOL code (when necessary) provided by them. ' +\n",
    "                    'In every round, you provide your answer, you need to combine with your previous answer and update them. ' +\n",
    "                    'Your answer needs to be correctly written in EOL. ' +\n",
    "                    'Do not include any other contents that are not provided to you. ' +\n",
    "                    'If no further answer can be provided, repeat your last answer. ' +\n",
    "                    'Please only provide EOL code in your answers. Do not explain (no ```). ',\n",
    "                    description='A Model_Summariser to summerise the code from Model_Checker.'\n",
    "                )\n",
    "        \n",
    "                #Json_Generator to generate a json for traceability.\n",
    "                self.json_generator = ConversableAgent(\n",
    "                    name=\"Json_Generator\",\n",
    "                    llm_config={\n",
    "                        \"temperature\": 0.5,\n",
    "                        \"config_list\": super().getConfigList(),\n",
    "                        \"timeout\": 600000,\n",
    "                        \"cache_seed\": None,\n",
    "                    },\n",
    "                    system_message=\n",
    "                    'You are an expert in Model Driven Engineering (MDE). ' +\n",
    "                    'You are experienced in creating EMF (Eclipse Modelling Framework) models using languages provided by the Eclipse Epsilon platform. ' +\n",
    "                    'Specifically, you use the Epsilon Object Language (EOL) to create EMF models programmatically. ' +\n",
    "                    'Your job is to generate a JSON element by analysing the EOL code (provided by Model_Checker) for model creation, and the requirement provided by User every round. ' +\n",
    "                    'The metamodel (created using the Emfatic language) for the model to be created is here: ' + dsl +\n",
    "                    'Here are some guidance to help you: ' + chain_of_thought_model_trace +\n",
    "                    'Your answer should be in the following JSON format : ' +\n",
    "                    '{\"requirement_gid\" : ${the gid of the requirement provided by User}, ' +\n",
    "                    '\"Model_Element\" : ${the name of the class created by the EOL code}, ' +\n",
    "                    '\"Model_Element_id\" : ${the name or the id of the object created for the above class}, ' +\n",
    "                    '\"Model_attribute\": ${the name of the attributes set by the EOL code}, ' +\n",
    "                    '\"Attribute_value\": ${the value of the above attribute set by the EOL code}, ' +\n",
    "                    '\"Model_references\":${the name of the references set by the EOL code} } ' +\n",
    "                    '\"Reference_value\":${the name or the id of the value set for the above reference} } ' +\n",
    "                    'If the EOL code creates multiple model elements, please create a JSON list with multiple JSON entries, like so: [$JSON entry, $JSON entry, ... $JSON entry].' +\n",
    "                    ' The Output format is JSON only, no markdown permitted (no ```), no explain.',\n",
    "                    description='A Json_Generator to generate a JSON element based on the EOL code provided by Model_Checker and the requirement provided by User every round.'\n",
    "                )       \n",
    "                #Create a groupchat to organise the agents\n",
    "                self.groupchat = autogen.GroupChat(\n",
    "                    agents=[self.user, self.model_Creator, self.model_Checker, self.model_Refactorer, self.json_generator],\n",
    "                    messages=[],\n",
    "                    speaker_selection_method='round_robin',\n",
    "                    max_round=1000,\n",
    "                    send_introductions=True\n",
    "                )\n",
    "                super().init_group_chat_manager()\n",
    "                model_creator = Model_Creator()\n",
    "                chat_results = model_creator.user.initiate_chat(\n",
    "                    model_creator.groupt_chat_manager,\n",
    "                    # start chat with the first item of the file\n",
    "                    # message=\"Let us start creating the EOL code for creating a EMF model based on the requirements provided by User. \" +\n",
    "                    # \"Model_Creator will write the EOL code, Model_Checker will check the correctness of the code, Model_Refactorer will organise and refactor the code. \" +\n",
    "                    # \"The JSON_Generator will generate the JSON file containing trace information.\",\n",
    "                    clear_history=True,\n",
    "                )\n",
    "    \n",
    "                model_creator.storeJSON(chat_results, \"Json_Generator\", f\"result/EMF_Model_trace_result/multi_EOL_trace_result_{i+1}.json\", \"model_trace\")\n",
    "    \n",
    "                data = chat_results.chat_history\n",
    "    \n",
    "                # Extract the last content for 'Model_Summariser'\n",
    "                last_model_summariser_content = next(\n",
    "                    (entry['content'] for entry in reversed(data) if entry.get('name') == 'Model_Refactorer'), None)\n",
    "    \n",
    "                if last_model_summariser_content:\n",
    "                    with open(f'result/EMF_Model_result/multi_eol_result_{i+1}.eol', 'w', encoding='utf-8') as file:\n",
    "                        file.write(last_model_summariser_content)\n",
    "                # Print the last content\n",
    "                print(last_model_summariser_content)"
   ],
   "id": "eddd5533e16e9798",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "EMF_Model_Creation(2)"
   ],
   "id": "2935be8dca307a8",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
